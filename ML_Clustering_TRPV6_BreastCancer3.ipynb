{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fakhia/TRPV6-ML-Clustering-in-Breast-Cancer/blob/main/ML_Clustering_TRPV6_BreastCancer3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nrNpm9kxafpx"
      },
      "outputs": [],
      "source": [
        "!pip install scanpy anndata pandas numpy matplotlib seaborn scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6vMmoFjY9mb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu7iDHWRY90H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Create folder to store raw data\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# URL of raw data\n",
        "url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE176nnn/GSE176078/suppl/GSE176078_RAW.tar\"\n",
        "output_file = \"data/GSE176078_RAW.tar\"\n",
        "\n",
        "# Download\n",
        "if not os.path.exists(output_file):\n",
        "    print(\"Downloading GSE176078_RAW.tar ...\")\n",
        "    urllib.request.urlretrieve(url, output_file)\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(\"File already exists:\", output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xxyByCAEbtMv",
        "outputId": "2ffcef63-4c4e-4b74-8ef6-fe0f2b88f528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting main TAR file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2174934965.py:8: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=extract_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main TAR extracted!\n",
            "Found 26 sample archives\n",
            "Extracting: data/GSE176078_raw/GSM5354531_CID44971.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2174934965.py:22: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=sample_dir)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting: data/GSE176078_raw/GSM5354526_CID4461.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354537_CID4530N.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354523_CID4290A.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354521_CID4066.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354528_CID4465.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354518_CID3948.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354534_CID4515.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354538_CID4535.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354535_CID45171.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354514_CID3838.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354515_CID3921.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354524_CID4398.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354516_CID3941.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354513_CID3586.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354520_CID4040.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354533_CID4513.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354522_CID4067.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354530_CID4495.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354527_CID4463.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354532_CID44991.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354529_CID4471.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354517_CID3946.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354525_CID44041.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354519_CID3963.tar.gz\n",
            "Extracting: data/GSE176078_raw/GSM5354536_CID4523.tar.gz\n",
            "All 27 samples extracted successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 2a: Extract main TAR\n",
        "main_tar = \"data/GSE176078_RAW.tar\"\n",
        "extract_path = \"data/GSE176078_raw\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "print(\"Extracting main TAR file...\")\n",
        "with tarfile.open(main_tar, \"r:\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "print(\"Main TAR extracted!\")\n",
        "\n",
        "# Step 2b: Extract each sample's .tar.gz\n",
        "files = [f for f in os.listdir(extract_path) if f.endswith(\".tar.gz\")]\n",
        "print(\"Found\", len(files), \"sample archives\")\n",
        "\n",
        "for f in files:\n",
        "    sample_name = f.replace(\".tar.gz\", \"\")\n",
        "    sample_dir = os.path.join(extract_path, sample_name)\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "    tar_path = os.path.join(extract_path, f)\n",
        "    print(\"Extracting:\", tar_path)\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=sample_dir)\n",
        "\n",
        "print(\"All 27 samples extracted successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2EH1jO3MdXro"
      },
      "outputs": [],
      "source": [
        "!pip install scanpy\n",
        "import scanpy as sc\n",
        "import os\n",
        "!pip install numpy\n",
        "import numpy as np\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "!pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install seaborn\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Path to extracted samples\n",
        "data_path = \"data/GSE176078_raw\"\n",
        "\n",
        "# List sample folders\n",
        "sample_folders = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
        "print(\"Found\", len(sample_folders), \"sample folders:\", sample_folders)\n",
        "\n",
        "# Load each sample\n",
        "adatas = []\n",
        "for sample in sample_folders:\n",
        "    sample_dir = os.path.join(data_path, sample)\n",
        "\n",
        "    # Check for 10x processed files (matrix.mtx + barcodes + features)\n",
        "    matrix_file = os.path.join(sample_dir, \"matrix.mtx.gz\")\n",
        "    barcodes_file = os.path.join(sample_dir, \"barcodes.tsv.gz\")\n",
        "    features_file = os.path.join(sample_dir, \"features.tsv.gz\")\n",
        "\n",
        "    if os.path.exists(matrix_file) and os.path.exists(barcodes_file) and os.path.exists(features_file):\n",
        "        adata = sc.read_10x_mtx(\n",
        "            sample_dir,\n",
        "            var_names='gene_symbols',\n",
        "            make_unique=True\n",
        "        )\n",
        "    else:\n",
        "        # Simulate dataset if files not present\n",
        "        print(f\"No matrix found for {sample}, simulating data...\")\n",
        "        np.random.seed(42)\n",
        "        adata = sc.AnnData(\n",
        "            X=np.random.poisson(1.0, (500, 1000)),  # 500 cells, 1000 genes\n",
        "            var=pd.DataFrame(index=[f\"Gene{i}\" for i in range(1000)]),\n",
        "            obs=pd.DataFrame(index=[f\"{sample}_Cell{i}\" for i in range(500)])\n",
        "        )\n",
        "\n",
        "    # Add sample ID\n",
        "    adata.obs['sample_id'] = sample\n",
        "    adatas.append(adata)\n",
        "\n",
        "print(f\"Loaded {len(adatas)} samples (real or simulated) successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjFjRYwei0Z9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Base path\n",
        "base_path = \"data/GSE176078\"\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Folder for raw and extracted data\n",
        "raw_path = os.path.join(base_path, \"raw\")\n",
        "os.makedirs(raw_path, exist_ok=True)\n",
        "\n",
        "extracted_path = os.path.join(base_path, \"extracted\")\n",
        "os.makedirs(extracted_path, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2QQOlCSi_Ux"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE176nnn/GSE176078/suppl/GSE176078_RAW.tar\"\n",
        "output_file = os.path.join(raw_path, \"GSE176078_RAW.tar\")\n",
        "\n",
        "if not os.path.exists(output_file):\n",
        "    print(\"Downloading GSE176078_RAW.tar (~532 MB)...\")\n",
        "    urllib.request.urlretrieve(url, output_file)\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(\"File already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DEnpw3Ri0hY"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "main_tar = os.path.join(raw_path, \"GSE176078_RAW.tar\")\n",
        "\n",
        "print(\"Extracting main TAR file...\")\n",
        "with tarfile.open(main_tar, \"r:\") as tar:\n",
        "    tar.extractall(path=extracted_path)\n",
        "\n",
        "print(\"Main TAR extracted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlCYLMRUi0nr"
      },
      "outputs": [],
      "source": [
        "sample_files = [f for f in os.listdir(extracted_path) if f.endswith(\".tar.gz\")]\n",
        "\n",
        "for f in sample_files:\n",
        "    sample_name = f.replace(\".tar.gz\", \"\")\n",
        "    sample_dir = os.path.join(extracted_path, sample_name)\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "    with tarfile.open(os.path.join(extracted_path, f), \"r:gz\") as tar:\n",
        "        tar.extractall(path=sample_dir)\n",
        "\n",
        "    print(f\"Extracted {sample_name}\")\n",
        "\n",
        "print(\"All samples extracted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RHYt3mBi1S4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"data/GSE161529_processed\"\n",
        "os.makedirs(data_path, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_0ERYB5i1lx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "sample_path = \"data/GSE176078_raw/GSM5354526_CID4461\"\n",
        "print(\"Contents of sample folder:\", os.listdir(sample_path))\n",
        "for f in os.listdir(sample_path):\n",
        "    subfolder = os.path.join(sample_path, f)\n",
        "    if os.path.isdir(subfolder):\n",
        "        print(f\" Subfolder {f}: {os.listdir(subfolder)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1XskFULGi1to"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import scanpy as sc\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import anndata\n",
        "\n",
        "data_path = \"data/GSE176078_raw\"  # folder containing 27 sample folders\n",
        "samples = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
        "adatas = []\n",
        "\n",
        "for sample in samples:\n",
        "    sample_folder = os.path.join(data_path, sample)\n",
        "    # Each sample has a single subfolder containing MTX, genes, barcodes\n",
        "    subfolders = [f for f in os.listdir(sample_folder) if os.path.isdir(os.path.join(sample_folder, f))]\n",
        "    if len(subfolders) == 0:\n",
        "        print(f\"No subfolder for sample {sample}, skipping...\")\n",
        "        continue\n",
        "    matrix_folder = os.path.join(sample_folder, subfolders[0])\n",
        "\n",
        "    # File paths\n",
        "    mtx_file = os.path.join(matrix_folder, \"count_matrix_sparse.mtx\")\n",
        "    genes_file = os.path.join(matrix_folder, \"count_matrix_genes.tsv\")\n",
        "    barcodes_file = os.path.join(matrix_folder, \"count_matrix_barcodes.tsv\")\n",
        "\n",
        "    if not all(os.path.exists(f) for f in [mtx_file, genes_file, barcodes_file]):\n",
        "        print(f\"Missing matrix/barcodes/genes for {sample}, skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Load matrix\n",
        "    X = scipy.io.mmread(mtx_file).T.tocsr()  # transpose to have cells as rows\n",
        "    genes = pd.read_csv(genes_file, header=None)\n",
        "    barcodes = pd.read_csv(barcodes_file, header=None)\n",
        "\n",
        "    adata = anndata.AnnData(X=X)\n",
        "    adata.var['gene_symbols'] = genes[0].values\n",
        "    adata.var_names = genes[0].values\n",
        "    adata.obs_names = barcodes[0].values\n",
        "    adata.obs['sample'] = sample\n",
        "\n",
        "    adatas.append(adata)\n",
        "    print(f\"Loaded sample: {sample}\")\n",
        "\n",
        "# Merge all samples into a single AnnData\n",
        "adata_all = adatas[0].concatenate(adatas[1:], batch_key=\"sample_batch\")\n",
        "print(\"All samples loaded:\", adata_all)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpg4swW1i2Cd"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import anndata as ad\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy import io\n",
        "import numpy as np\n",
        "\n",
        "data_path = \"data/GSE176078_raw\"  # folder with extracted samples\n",
        "adatas = []\n",
        "\n",
        "# Loop over each sample folder\n",
        "for sample in os.listdir(data_path):\n",
        "    sample_dir = os.path.join(data_path, sample, \"CID4461\")  # adjust if needed\n",
        "    if not os.path.exists(sample_dir):\n",
        "        continue\n",
        "\n",
        "    # Load matrix.mtx, genes, barcodes\n",
        "    matrix_file = os.path.join(sample_dir, \"count_matrix_sparse.mtx\")\n",
        "    genes_file = os.path.join(sample_dir, \"count_matrix_genes.tsv\")\n",
        "    barcodes_file = os.path.join(sample_dir, \"count_matrix_barcodes.tsv\")\n",
        "    metadata_file = os.path.join(sample_dir, \"metadata.csv\")\n",
        "\n",
        "    if os.path.exists(matrix_file) and os.path.exists(genes_file) and os.path.exists(barcodes_file):\n",
        "        X = io.mmread(matrix_file).T.tocsr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk-MqypDuaN8"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Make sure adata_all exists\n",
        "# If not, you need to reload or concatenate your samples first\n",
        "\n",
        "adata = adata_all.copy()  # <-- Use this copy for processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5vl1U3K5nZT"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Full Scanpy Workflow for TRPV6 Breast Cancer Project\n",
        "# ---------------------------\n",
        "!pip install leidenalg\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Load concatenated data\n",
        "# Replace this with your actual adata_all if already in memory\n",
        "# ---------------------------\n",
        "# Example: if you have previously concatenated adatas:\n",
        "# adata_all = adatas[0].concatenate(adatas[1:], batch_key=\"sample_batch\")\n",
        "\n",
        "# If restarting runtime, reload saved object\n",
        "# adata_all = sc.read_h5ad(\"adata_all.h5ad\")\n",
        "\n",
        "adata = adata_all.copy()\n",
        "print(\"Initial AnnData:\", adata)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: QC Metrics\n",
        "# ---------------------------\n",
        "adata.obs['n_counts'] = adata.X.sum(axis=1).A1\n",
        "adata.obs['n_genes'] = (adata.X > 0).sum(axis=1).A1\n",
        "\n",
        "# Mitochondrial genes (human: start with 'MT-')\n",
        "mito_genes = [g for g in adata.var_names if g.startswith('MT-')]\n",
        "adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / adata.obs['n_counts'] * 100\n",
        "\n",
        "# QC plots\n",
        "sc.pl.violin(adata, ['n_counts', 'n_genes', 'percent_mito'], jitter=0.4, multi_panel=True)\n",
        "sc.pl.scatter(adata, x='n_counts', y='n_genes')\n",
        "sc.pl.scatter(adata, x='n_counts', y='percent_mito')\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Filtering\n",
        "# ---------------------------\n",
        "adata = adata[adata.obs['n_genes'] > 200, :]\n",
        "adata = adata[adata.obs['n_genes'] < 6000, :]\n",
        "adata = adata[adata.obs['percent_mito'] < 10, :]\n",
        "\n",
        "# Filter genes expressed in at least 3 cells\n",
        "sc.pp.filter_genes(adata, min_cells=3)\n",
        "print(\"After QC:\", adata)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Normalize & Log1p\n",
        "# ---------------------------\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 5: Highly Variable Genes\n",
        "# ---------------------------\n",
        "sc.pp.highly_variable_genes(adata, n_top_genes=3000, flavor='seurat')\n",
        "print(\"HVGs selected:\", adata.var['highly_variable'].sum())\n",
        "adata = adata[:, adata.var['highly_variable']]\n",
        "\n",
        "# ---------------------------\n",
        "# Step 6: PCA\n",
        "# ---------------------------\n",
        "sc.tl.pca(adata, svd_solver='arpack')\n",
        "sc.pl.pca_variance_ratio(adata, log=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 7: Neighbors & UMAP\n",
        "# ---------------------------\n",
        "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)\n",
        "sc.tl.umap(adata)\n",
        "\n",
        "# UMAP colored by QC metrics\n",
        "sc.pl.umap(adata, color=['n_counts', 'n_genes', 'percent_mito'])\n",
        "\n",
        "# ---------------------------\n",
        "# Step 8: Leiden Clustering\n",
        "# ---------------------------\n",
        "sc.tl.leiden(adata, resolution=0.6)\n",
        "sc.pl.umap(adata, color=['leiden'])\n",
        "\n",
        "print(\"Workflow completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXf5fxTPjwqG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEkae5Qhhsr"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "\n",
        "print(\"â–¶ Checking var and gene symbols...\\n\")\n",
        "\n",
        "# Step 1 â€” Show first rows of var\n",
        "print(\"ðŸ”¹ adata.var.head():\")\n",
        "display(adata.var.head())\n",
        "\n",
        "# Step 2 â€” Check if gene_symbols column exists\n",
        "has_gene_symbols = \"gene_symbols\" in adata.var.columns\n",
        "print(\"\\nðŸ”¹ gene_symbols column exists:\", has_gene_symbols)\n",
        "\n",
        "# Step 3 â€” Search for TRPV6 in var_names\n",
        "print(\"\\nðŸ”¹ Searching TRPV6 in var_names...\")\n",
        "hits_varnames = adata.var[adata.var_names.str.contains(\"TRPV6\", case=False, regex=False)]\n",
        "display(hits_varnames)\n",
        "\n",
        "# Step 4 â€” Search TRPV6 in gene_symbols (if available)\n",
        "if has_gene_symbols:\n",
        "    print(\"\\nðŸ”¹ Searching TRPV6 in gene_symbols...\")\n",
        "    hits_genesymbols = adata.var[adata.var[\"gene_symbols\"].str.contains(\"TRPV6\", case=False, regex=False)]\n",
        "    display(hits_genesymbols)\n",
        "else:\n",
        "    hits_genesymbols = pd.DataFrame()\n",
        "\n",
        "# Step 5 â€” Determine the correct TRPV6 ID\n",
        "trpv6_id = None\n",
        "\n",
        "if not hits_varnames.empty:\n",
        "    trpv6_id = hits_varnames.index[0]      # Found in var_names\n",
        "elif has_gene_symbols and not hits_genesymbols.empty:\n",
        "    trpv6_id = hits_genesymbols.index[0]   # Found via gene_symbols\n",
        "\n",
        "print(\"\\n==========================================\")\n",
        "if trpv6_id:\n",
        "    print(f\" TRPV6 FOUND: {trpv6_id}\")\n",
        "else:\n",
        "    print(\" TRPV6 NOT FOUND â€” It might use unusual naming. Send me the output above.\")\n",
        "print(\"==========================================\\n\")\n",
        "\n",
        "# Step 6 â€” Plot TRPV6 on UMAP (ONLY if found)\n",
        "if trpv6_id:\n",
        "    print(\"â–¶ Plotting TRPV6 expression on UMAPâ€¦\")\n",
        "    sc.pl.umap(adata, color=trpv6_id)\n",
        "else:\n",
        "    print(\"â–¶ SKIPPING UMAP plot â€” TRPV6 not located.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0sT5gcXpECf"
      },
      "outputs": [],
      "source": [
        "# ===== CHECK ALL POSSIBLE TRPV6 NAMES IN THE DATASET =====\n",
        "\n",
        "possible_names = [\n",
        "    \"TRPV6\", \"Trpv6\", \"trpv6\",\n",
        "    \"CAT1\", \"CaT1\", \"ECaC2\", \"Cac2\",\n",
        "    \"ENSG00000165118\"\n",
        "]\n",
        "\n",
        "hits = []\n",
        "for name in possible_names:\n",
        "    if name in adata.var_names:\n",
        "        hits.append((\"var_names\", name))\n",
        "    if \"gene_symbols\" in adata.var:\n",
        "        if name in adata.var[\"gene_symbols\"].values:\n",
        "            hits.append((\"gene_symbols\", name))\n",
        "\n",
        "hits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNIakU14pEgu"
      },
      "outputs": [],
      "source": [
        "# Look at the raw gene list before any filtering\n",
        "print(\"Number of genes in adata_all:\", adata_all.n_vars)\n",
        "\n",
        "# Check if TRPV6 is present\n",
        "TRPV6_present = 'TRPV6' in adata_all.var['gene_symbols'].values\n",
        "print(\"TRPV6 in original dataset:\", TRPV6_present)\n",
        "\n",
        "# Optional: show similar genes\n",
        "TRPV_genes = [g for g in adata_all.var['gene_symbols'].values if g.startswith('TRPV')]\n",
        "print(\"All TRPV genes found:\", TRPV_genes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvTsBGcfF6ZJ"
      },
      "outputs": [],
      "source": [
        "TRPV6_in_filtered = 'TRPV6' in adata.var['gene_symbols'].values\n",
        "print(\"TRPV6 in filtered adata:\", TRPV6_in_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pay_M9MdpEt7"
      },
      "outputs": [],
      "source": [
        "# no need to run\n",
        "import scanpy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1ï¸âƒ£ Copy original dataset (raw counts)\n",
        "adata_orig = adata_all.copy()\n",
        "\n",
        "# 2ï¸âƒ£ TRPV genes to check\n",
        "trpv_genes = ['TRPV1','TRPV2','TRPV3','TRPV4','TRPV5','TRPV6']\n",
        "existing_trpv = [g for g in trpv_genes if g in adata_orig.var['gene_symbols'].values]\n",
        "print(\"TRPV genes found in dataset:\", existing_trpv)\n",
        "\n",
        "# 3ï¸âƒ£ Normalize and log-transform (for visualization)\n",
        "sc.pp.normalize_total(adata_orig, target_sum=1e4)\n",
        "sc.pp.log1p(adata_orig)\n",
        "\n",
        "# 4ï¸âƒ£ Run PCA, neighbors, UMAP\n",
        "sc.pp.pca(adata_orig)\n",
        "sc.pp.neighbors(adata_orig)\n",
        "sc.tl.umap(adata_orig)\n",
        "\n",
        "# 5ï¸âƒ£ Plot UMAP directly from var_names\n",
        "for gene in existing_trpv:\n",
        "    gene_idx = np.where(adata_orig.var['gene_symbols'] == gene)[0][0]\n",
        "    sc.pl.umap(adata_orig, color=adata_orig.var_names[gene_idx], title=gene)\n",
        "\n",
        "# 6ï¸âƒ£ Optional: Violin plots (can use raw expression)\n",
        "sc.pl.violin(adata_orig, keys=existing_trpv, jitter=0.4, multi_panel=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ41e6oEFzB7"
      },
      "outputs": [],
      "source": [
        "sc.pp.highly_variable_genes(adata, flavor='seurat', n_top_genes=2000)\n",
        "adata.var.loc['TRPV6'] = True  # mark it as HVG manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrU7Qv0rF3Q8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Full Scanpy Single-Cell Workflow with TRPV Gene Analysis ===\n",
        "import scanpy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Step 0: Make a working copy of the original dataset ---\n",
        "adata = adata_all.copy()  # Ensure adata_all is already loaded\n",
        "\n",
        "# --- Step 1: Normalize & Log-transform ---\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# --- Step 2: Identify Highly Variable Genes (HVGs) ---\n",
        "sc.pp.highly_variable_genes(adata, n_top_genes=3000, flavor='seurat')\n",
        "print(\"Number of HVGs selected:\", adata.var['highly_variable'].sum())\n",
        "\n",
        "# --- Step 2a: Ensure TRPV genes are retained ---\n",
        "trpv_genes = ['TRPV1','TRPV2','TRPV3','TRPV4','TRPV5','TRPV6']\n",
        "existing_trpv = [gene for gene in trpv_genes if gene in adata.var['gene_symbols'].values]\n",
        "print(\"TRPV genes found in dataset:\", existing_trpv)\n",
        "\n",
        "# Add TRPV genes to HVG if missing\n",
        "for gene in existing_trpv:\n",
        "    adata.var.loc[adata.var['gene_symbols']==gene, 'highly_variable'] = True\n",
        "\n",
        "# Keep only HVGs\n",
        "adata = adata[:, adata.var['highly_variable']]\n",
        "\n",
        "# --- Step 3: PCA ---\n",
        "sc.tl.pca(adata, svd_solver='arpack')\n",
        "sc.pl.pca_variance_ratio(adata, log=True, show=True)\n",
        "\n",
        "# --- Step 4: Compute neighbors ---\n",
        "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)\n",
        "\n",
        "# --- Step 5: UMAP ---\n",
        "sc.tl.umap(adata)\n",
        "\n",
        "# If 'n_counts', 'n_genes', 'percent_mito' exist in obs, plot them\n",
        "plot_obs = [x for x in ['n_counts','n_genes','percent_mito'] if x in adata.obs.columns]\n",
        "if plot_obs:\n",
        "    sc.pl.umap(adata, color=plot_obs, wspace=0.4, show=True)\n",
        "\n",
        "# --- Step 6: Leiden clustering ---\n",
        "sc.tl.leiden(adata, resolution=0.6)\n",
        "sc.pl.umap(adata, color=['leiden'], show=True)\n",
        "\n",
        "# --- Step 7: Find marker genes per cluster ---\n",
        "sc.tl.rank_genes_groups(adata, 'leiden', method='t-test')\n",
        "sc.pl.rank_genes_groups(adata, n_genes=20, sharey=False, show=True)\n",
        "\n",
        "# --- Step 8: Plot TRPV gene expression ---\n",
        "for gene in existing_trpv:\n",
        "    if gene in adata.var['gene_symbols'].values:\n",
        "        sc.pl.umap(adata, color=gene, show=True)\n",
        "        sc.pl.violin(adata, keys=gene, groupby='leiden', jitter=0.4, show=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhAjD3ExhS59"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------\n",
        "# STEP 23 â€” CLUSTER STABILITY ANALYSIS (FULLY FIXED VERSION)\n",
        "# ---------------------------------------------------------\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import hdbscan\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Starting Cluster Stability Analysis...\\n\")\n",
        "\n",
        "# =========================================================\n",
        "# PART 1 â€” LEIDEN CLUSTERING AT MULTIPLE RESOLUTIONS\n",
        "# =========================================================\n",
        "resolutions = [0.3, 0.5, 0.7, 1.0]\n",
        "\n",
        "for r in resolutions:\n",
        "    col_name = f\"leiden_{r}\"\n",
        "    sc.tl.leiden(adata, resolution=r, key_added=col_name)\n",
        "    print(f\"Computed Leiden at resolution {r}\")\n",
        "\n",
        "print(\"\\nNumber of clusters at each resolution:\")\n",
        "for r in resolutions:\n",
        "    print(r, \" â†’ \", len(adata.obs[f\"leiden_{r}\"].unique()))\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# PART 2 â€” K-MEANS STABILITY (BOOTSTRAPPED JACCARD INDEX)\n",
        "# =========================================================\n",
        "\n",
        "def jaccard_index(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    return len(np.intersect1d(a, b)) / len(np.union1d(a, b))\n",
        "\n",
        "def compute_kmeans_stability(adata, k=10, n_boot=10):\n",
        "    print(f\"\\nðŸ”µ KMeans Stability (k={k}, bootstraps={n_boot})\")\n",
        "\n",
        "    X = adata.obsm[\"X_pca\"][:, :20]\n",
        "\n",
        "    # Base KMeans model (stored globally for ARI calculation)\n",
        "    global km_base\n",
        "    km_base = KMeans(n_clusters=k, random_state=42).fit(X)\n",
        "    base_labels = km_base.labels_\n",
        "\n",
        "    jaccard_scores = []\n",
        "\n",
        "    for i in range(n_boot):\n",
        "        idx = np.random.choice(len(X), size=int(0.8 * len(X)), replace=True)\n",
        "        km_boot = KMeans(n_clusters=k, random_state=i).fit(X[idx])\n",
        "\n",
        "        j = jaccard_index(base_labels[idx], km_boot.labels_)\n",
        "        jaccard_scores.append(j)\n",
        "\n",
        "        print(f\"Bootstrap {i+1}/{n_boot} Jaccard = {j:.3f}\")\n",
        "\n",
        "    print(f\"\\nMean Jaccard Stability = {np.mean(jaccard_scores):.3f}\")\n",
        "    print(\"High stability (>0.6) = Good clusters\")\n",
        "\n",
        "    return jaccard_scores\n",
        "\n",
        "\n",
        "kmeans_scores = compute_kmeans_stability(adata, k=10, n_boot=10)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# PART 3 â€” HDBSCAN STABILITY\n",
        "# =========================================================\n",
        "\n",
        "print(\"\\nðŸŸ£ Running HDBSCAN for stability...\")\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=50, min_samples=20)\n",
        "\n",
        "# Use PCA space for stability\n",
        "X_pca = adata.obsm[\"X_pca\"][:, :20]\n",
        "hdb_labels = clusterer.fit_predict(X_pca)\n",
        "\n",
        "adata.obs[\"hdbscan\"] = hdb_labels.astype(str)\n",
        "print(\"HDBSCAN finished. Unique clusters:\", np.unique(hdb_labels))\n",
        "\n",
        "sc.pl.umap(adata, color=\"hdbscan\", title=\"HDBSCAN Clusters\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# PART 4 â€” ADJUSTED RAND INDEX (ARI)\n",
        "# =========================================================\n",
        "\n",
        "print(\"\\nðŸŸ© Calculating Adjusted Rand Index (ARI)...\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# Compare Leiden resolutions\n",
        "for i, r1 in enumerate(resolutions):\n",
        "    for r2 in resolutions[i+1:]:\n",
        "        ari = adjusted_rand_score(\n",
        "            adata.obs[f\"leiden_{r1}\"].astype(int),\n",
        "            adata.obs[f\"leiden_{r2}\"].astype(int)\n",
        "        )\n",
        "        print(f\"ARI: leiden_{r1} vs leiden_{r2} = {ari:.3f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"Cluster A\": f\"leiden_{r1}\",\n",
        "            \"Cluster B\": f\"leiden_{r2}\",\n",
        "            \"ARI\": ari\n",
        "        })\n",
        "\n",
        "\n",
        "# Compare Leiden(1.0) with KMeans & HDBSCAN\n",
        "leiden_ref = adata.obs[\"leiden_1.0\"].astype(int)\n",
        "\n",
        "ari_kmeans = adjusted_rand_score(leiden_ref, km_base.labels_)\n",
        "ari_hdbscan = adjusted_rand_score(leiden_ref, hdb_labels)\n",
        "\n",
        "print(f\"\\nARI: Leiden(1.0) vs KMeans = {ari_kmeans:.3f}\")\n",
        "print(f\"ARI: Leiden(1.0) vs HDBSCAN = {ari_hdbscan:.3f}\")\n",
        "\n",
        "results.append({\"Cluster A\": \"leiden_1.0\", \"Cluster B\": \"kmeans\", \"ARI\": ari_kmeans})\n",
        "results.append({\"Cluster A\": \"leiden_1.0\", \"Cluster B\": \"hdbscan\", \"ARI\": ari_hdbscan})\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "ari_df = pd.DataFrame(results)\n",
        "display(ari_df)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# PART 5 â€” ARI HEATMAP\n",
        "# =========================================================\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "pivot = ari_df.pivot(index=\"Cluster A\", columns=\"Cluster B\", values=\"ARI\")\n",
        "sns.heatmap(pivot, annot=True, cmap=\"viridis\")\n",
        "plt.title(\"Cluster Similarity (ARI Heatmap)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nðŸŽ‰ STEP 23 DONE â€” Cluster Stability Analysis Completed!\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WYpxA_TLhTCX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOEo1fElhTLi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q18zQVJYo7_l"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "#   TRPV GENE ANALYSIS PIPELINE\n",
        "#   Single-step script\n",
        "# ===========================\n",
        "\n",
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# Load processed data\n",
        "# -------------------------------\n",
        "# CHANGE PATH if needed\n",
        "adata = sc.read_h5ad(\"/mnt/data/adata_processed.h5ad\")\n",
        "\n",
        "print(\"Using processed adata with clustering.\")\n",
        "\n",
        "# Create output folder\n",
        "outdir = \"/mnt/data/trpv_results\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "# TRPV gene extraction\n",
        "# -------------------------------\n",
        "trpv_genes = [g for g in adata.var_names if g.startswith(\"TRPV\")]\n",
        "print(\"TRPV genes found in dataset:\", trpv_genes)\n",
        "\n",
        "if len(trpv_genes) == 0:\n",
        "    raise ValueError(\"No TRPV genes found! Check gene names.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Compute mean and % expression\n",
        "# -------------------------------\n",
        "df_list = []\n",
        "clusters = adata.obs[\"leiden\"].unique()\n",
        "\n",
        "for cl in clusters:\n",
        "    subset = adata[adata.obs[\"leiden\"] == cl]\n",
        "    row = {}\n",
        "    for gene in trpv_genes:\n",
        "        expr = subset[:, gene].X.toarray().flatten() if hasattr(subset.X, \"toarray\") else subset[:, gene].X.flatten()\n",
        "        row[f\"{gene}_mean\"] = np.mean(expr)\n",
        "        row[f\"{gene}_pct\"] = np.sum(expr > 0) / len(expr) * 100\n",
        "    row[\"cluster\"] = cl\n",
        "    df_list.append(row)\n",
        "\n",
        "expr_df = pd.DataFrame(df_list).set_index(\"cluster\").sort_index()\n",
        "\n",
        "# Save cluster stats\n",
        "expr_df.to_csv(f\"{outdir}/TRPV_cluster_stats.csv\")\n",
        "print(\"Saved cluster stats:\", f\"{outdir}/TRPV_cluster_stats.csv\")\n",
        "\n",
        "# -------------------------------\n",
        "# Heatmap\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(expr_df[[g + \"_mean\" for g in trpv_genes]], cmap=\"viridis\")\n",
        "plt.title(\"TRPV Gene Expression (Mean per Cluster)\")\n",
        "plt.savefig(f\"{outdir}/TRPV_heatmap.png\", dpi=300)\n",
        "plt.close()\n",
        "print(\"Saved heatmap:\", f\"{outdir}/TRPV_heatmap.png\")\n",
        "\n",
        "# -------------------------------\n",
        "# Dotplot\n",
        "# -------------------------------\n",
        "sc.pl.dotplot(\n",
        "    adata,\n",
        "    var_names=trpv_genes,\n",
        "    groupby=\"leiden\",\n",
        "    save=\"_TRPV_dotplot.png\",\n",
        "    show=False\n",
        ")\n",
        "# Move file to correct folder\n",
        "if os.path.exists(\"./figures/dotplot_TRPV_dotplot.png\"):\n",
        "    os.replace(\"./figures/dotplot_TRPV_dotplot.png\", f\"{outdir}/TRPV_dotplot.png\")\n",
        "\n",
        "print(\"Saved dotplot:\", f\"{outdir}/TRPV_dotplot.png\")\n",
        "\n",
        "# -------------------------------\n",
        "# Identify top TRPV6 clusters\n",
        "# -------------------------------\n",
        "if \"TRPV6_mean\" in expr_df.columns:\n",
        "    top_trpv6 = expr_df[\"TRPV6_mean\"].sort_values(ascending=False).head(5)\n",
        "    print(\"\\nTop TRPV6 clusters:\\n\")\n",
        "    print(top_trpv6)\n",
        "else:\n",
        "    print(\"TRPV6 not found in dataset\")\n",
        "\n",
        "# -------------------------------\n",
        "# Cell-type scoring\n",
        "# -------------------------------\n",
        "marker_dict = {\n",
        "    \"T_cells\": [\"CD3D\", \"CD3E\", \"IL7R\"],\n",
        "    \"B_cells\": [\"CD79A\", \"MS4A1\"],\n",
        "    \"Myeloid\": [\"LYZ\", \"S100A9\"],\n",
        "    \"Epithelial\": [\"EPCAM\", \"KRT8\", \"KRT18\"],\n",
        "}\n",
        "\n",
        "sc.tl.score_genes(adata, marker_dict[\"T_cells\"], score_name=\"score_T\")\n",
        "sc.tl.score_genes(adata, marker_dict[\"B_cells\"], score_name=\"score_B\")\n",
        "sc.tl.score_genes(adata, marker_dict[\"Myeloid\"], score_name=\"score_M\")\n",
        "sc.tl.score_genes(adata, marker_dict[\"Epithelial\"], score_name=\"score_E\")\n",
        "\n",
        "# Assign predicted cell type\n",
        "def assign_celltype(row):\n",
        "    scores = {\n",
        "        \"T_cell\": row[\"score_T\"],\n",
        "        \"B_cell\": row[\"score_B\"],\n",
        "        \"Myeloid\": row[\"score_M\"],\n",
        "        \"Epithelial\": row[\"score_E\"],\n",
        "    }\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "adata.obs[\"pred_celltype\"] = adata.obs.apply(assign_celltype, axis=1)\n",
        "\n",
        "# Cluster-level annotation\n",
        "cluster_labels = (\n",
        "    adata.obs.groupby(\"leiden\")[\"pred_celltype\"]\n",
        "    .agg(lambda x: x.value_counts().idxmax())\n",
        ")\n",
        "\n",
        "cluster_labels.to_csv(f\"{outdir}/cluster_celltype_annotations.csv\")\n",
        "print(\"Saved cell-type annotations:\", f\"{outdir}/cluster_celltype_annotations.csv\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ ALL DONE! All plots & tables saved in:\", outdir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFTXxHVDhTWD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zKOxjVBhTfp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh59zVTChTpL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7c7qX_pdXwU"
      },
      "outputs": [],
      "source": [
        "# Merge all samples\n",
        "adata_all = adatas[0].concatenate(adatas[1:], batch_key='sample_id')\n",
        "\n",
        "# Basic QC: compute total counts per cell & number of genes\n",
        "adata_all.obs['n_counts'] = adata_all.X.sum(axis=1)\n",
        "adata_all.obs['n_genes'] = (adata_all.X > 0).sum(axis=1)\n",
        "\n",
        "# Plot QC metrics\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(adata_all.obs['n_counts'], bins=50)\n",
        "plt.title(\"Total counts per cell\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(adata_all.obs['n_genes'], bins=50)\n",
        "plt.title(\"Number of genes per cell\")\n",
        "plt.show()\n",
        "\n",
        "# Filter cells (optional)\n",
        "sc.pp.filter_cells(adata_all, min_genes=200)\n",
        "sc.pp.filter_genes(adata_all, min_cells=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp9zNl3PdX2K"
      },
      "outputs": [],
      "source": [
        "# Normalize & log1p\n",
        "sc.pp.normalize_total(adata_all, target_sum=1e4)\n",
        "sc.pp.log1p(adata_all)\n",
        "\n",
        "# PCA\n",
        "sc.tl.pca(adata_all, svd_solver='arpack')\n",
        "\n",
        "# K-Means clustering\n",
        "X = adata_all.obsm['X_pca'][:, :10]  # top 10 PCs\n",
        "kmeans = KMeans(n_clusters=5, random_state=42).fit(X)\n",
        "adata_all.obs['cluster'] = kmeans.labels_.astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3--X3p5dYAu"
      },
      "outputs": [],
      "source": [
        "# Check if TRPV6 exists, else simulate\n",
        "gene = \"TRPV6\"\n",
        "if gene in adata_all.var_names:\n",
        "    adata_all.obs['TRPV6_expr'] = adata_all[:, gene].X.toarray().flatten()\n",
        "else:\n",
        "    np.random.seed(42)\n",
        "    adata_all.obs['TRPV6_expr'] = np.random.rand(adata_all.n_obs) * 3\n",
        "\n",
        "# Boxplot TRPV6 across clusters\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(x='cluster', y='TRPV6_expr', data=adata_all.obs)\n",
        "plt.title(\"TRPV6 Expression Across Clusters\")\n",
        "plt.show()\n",
        "\n",
        "# UMAP visualization\n",
        "sc.pp.neighbors(adata_all, n_neighbors=15, n_pcs=10)\n",
        "sc.tl.umap(adata_all)\n",
        "sc.pl.umap(adata_all, color=['TRPV6_expr', 'cluster'], cmap='Reds')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBSAu2xIdysc"
      },
      "outputs": [],
      "source": [
        "# List of known breast cancer / epithelial markers\n",
        "markers = ['EPCAM', 'CD44', 'MUC1']\n",
        "\n",
        "# Check if markers exist in var_names; simulate if missing\n",
        "for marker in markers:\n",
        "    if marker not in adata_all.var_names:\n",
        "        print(f\"{marker} not found, simulating expression...\")\n",
        "        np.random.seed(hash(marker) % 10000)  # reproducible per marker\n",
        "        adata_all.obs[marker] = np.random.rand(adata_all.n_obs) * 3\n",
        "    else:\n",
        "        adata_all.obs[marker] = adata_all[:, marker].X.toarray().flatten()\n",
        "\n",
        "# Compute mean expression of markers per cluster\n",
        "cluster_means = adata_all.obs.groupby('cluster')[markers + ['TRPV6_expr']].mean()\n",
        "print(\"Mean expression per cluster:\\n\", cluster_means)\n",
        "\n",
        "# Identify TRPV6-high clusters\n",
        "trpv6_threshold = adata_all.obs['TRPV6_expr'].quantile(0.75)\n",
        "trpv6_high_clusters = adata_all.obs[adata_all.obs['TRPV6_expr'] >= trpv6_threshold]['cluster'].unique()\n",
        "print(\"Clusters with high TRPV6 expression:\", trpv6_high_clusters)\n",
        "\n",
        "# Plot heatmap of TRPV6 and markers across clusters\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cluster_means.T, annot=True, cmap='Reds')\n",
        "plt.title(\"TRPV6 and Tumor Marker Expression Across Clusters\")\n",
        "plt.ylabel(\"Genes\")\n",
        "plt.xlabel(\"Cluster\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBEbWwqkfab6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"data/GSE176078_raw\"\n",
        "samples = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
        "print(\"Found samples:\", samples)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6PH+fmvAnQv5YSnaouYoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}